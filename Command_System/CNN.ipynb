{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    block_files = np.array(data['filenames'])\n",
    "    block_targets = np_utils.to_categorical(np.array(data['target']), 6)\n",
    "    return block_files, block_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('block_image/train')\n",
    "valid_files, valid_targets = load_dataset('block_image/valid')\n",
    "test_files, test_targets = load_dataset('block_image/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 total block categories.\n",
      "There are 1080 total block images.\n",
      "\n",
      "There are 989 training block images.\n",
      "There are 61 validation block images.\n",
      "There are 30 test block images.\n"
     ]
    }
   ],
   "source": [
    "# load list of dog names\n",
    "block_names = [item[20:-1] for item in sorted(glob(\"block_image/train/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total block categories.' % len(block_names))\n",
    "print('There are %s total block images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training block images.' % len(train_files))\n",
    "print('There are %d validation block images.' % len(valid_files))\n",
    "print('There are %d test block images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(28, 28))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['block_image/train/000.none/block_010912462113.jpg',\n",
       "       'block_image/train/000.none/block_010912462615.jpg',\n",
       "       'block_image/train/000.none/block_0109124517.jpg',\n",
       "       'block_image/train/000.none/block_01091246264.jpg',\n",
       "       'block_image/train/000.none/block_010912474417.jpg',\n",
       "       'block_image/train/005.gray/block_01091246160.jpg',\n",
       "       'block_image/train/001.red/block_010912473118.jpg',\n",
       "       'block_image/train/003.blue/block_010912474115.jpg',\n",
       "       'block_image/train/000.none/block_01091246272.jpg',\n",
       "       'block_image/train/003.blue/block_01091245211.jpg'], dtype='<U51')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 989/989 [00:00<00:00, 3011.61it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 2536.41it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 1929.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/KaoruOta/anaconda3/envs/tensorflow_py35/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 27, 27, 16)        208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 64)          8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 10,934\n",
      "Trainable params: 10,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add( Conv2D(16,  kernel_size = (2, 2),  input_shape=(28, 28, 3), activation = 'relu', strides = 1, padding = 'valid'))\n",
    "model.add( MaxPooling2D(pool_size = (2, 2),  strides = 2))\n",
    "model.add( Conv2D(32, kernel_size = (2, 2),  activation = 'relu', strides = 1, padding = 'valid'))\n",
    "model.add( MaxPooling2D(pool_size = (2, 2),  strides = 2))\n",
    "model.add( Conv2D(64, kernel_size = (2, 2),  activation = 'relu', strides = 1, padding = 'valid'))\n",
    "model.add( MaxPooling2D(pool_size = (2, 2),  strides = 2))\n",
    "model.add( GlobalAveragePooling2D())\n",
    "model.add( Dense(units = 6, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/KaoruOta/anaconda3/envs/tensorflow_py35/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 989 samples, validate on 61 samples\n",
      "Epoch 1/10\n",
      "989/989 [==============================] - 4s 4ms/step - loss: 0.8980 - acc: 0.7341 - val_loss: 1.9990 - val_acc: 0.1803\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.99904, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 2/10\n",
      "989/989 [==============================] - 3s 3ms/step - loss: 0.6154 - acc: 0.7947 - val_loss: 1.5654 - val_acc: 0.4098\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.99904 to 1.56544, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 3/10\n",
      "989/989 [==============================] - 3s 3ms/step - loss: 0.3859 - acc: 0.8696 - val_loss: 1.3572 - val_acc: 0.4754\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.56544 to 1.35717, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 4/10\n",
      "989/989 [==============================] - 3s 3ms/step - loss: 0.2703 - acc: 0.9070 - val_loss: 0.8886 - val_acc: 0.6557\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.35717 to 0.88855, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 5/10\n",
      "989/989 [==============================] - 3s 3ms/step - loss: 0.2096 - acc: 0.9191 - val_loss: 1.0184 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.88855\n",
      "Epoch 6/10\n",
      "989/989 [==============================] - 3s 3ms/step - loss: 0.1563 - acc: 0.9484 - val_loss: 0.5131 - val_acc: 0.8033\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.88855 to 0.51308, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 7/10\n",
      "989/989 [==============================] - 3s 3ms/step - loss: 0.1209 - acc: 0.9585 - val_loss: 0.3037 - val_acc: 0.8852\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.51308 to 0.30369, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 8/10\n",
      "989/989 [==============================] - 3s 3ms/step - loss: 0.0944 - acc: 0.9687 - val_loss: 0.4940 - val_acc: 0.7869\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.30369\n",
      "Epoch 9/10\n",
      "989/989 [==============================] - 3s 3ms/step - loss: 0.0855 - acc: 0.9727 - val_loss: 0.2648 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.30369 to 0.26476, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 10/10\n",
      "989/989 [==============================] - 3s 3ms/step - loss: 0.0672 - acc: 0.9808 - val_loss: 0.5012 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3fd18be0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=2, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.load_weights('saved_models/weights.best.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 1125.23it/s]\n"
     ]
    }
   ],
   "source": [
    "data = load_files('block_image/input')\n",
    "input_files = np.array(data['filenames'])\n",
    "input_tensors = paths_to_tensor(input_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.09406754e-07, 5.48371696e-04, 9.68392134e-01, 1.99562754e-03,\n",
       "        7.57026501e-05, 2.89875828e-02],\n",
       "       [2.26313250e-06, 2.26825569e-02, 2.00284690e-01, 3.79657256e-03,\n",
       "        4.40179184e-03, 7.68832088e-01],\n",
       "       [2.51757548e-09, 6.00552484e-02, 3.50624009e-06, 1.85531723e-09,\n",
       "        9.39939260e-01, 2.00714157e-06],\n",
       "       [9.99764502e-01, 1.10290175e-05, 4.78616494e-05, 4.94509732e-05,\n",
       "        1.26930434e-04, 9.98632643e-08]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input_tensors\n",
    "result = model.predict_proba(input_tensors, batch_size = 2)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 90.0000%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "block_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(block_predictions)==np.argmax(test_targets, axis=1))/len(block_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
